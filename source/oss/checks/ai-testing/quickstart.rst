==========
Quickstart
==========

This guide will walk you through creating your first test case with Giskard Checks in under 5 minutes.


A simple example
----------------

Let's consider a simple question-answering bot. We want to test that the answers of our bot are correct according to some context information.

In the ``checks`` framework, all tests are performed on static representation of all data exchanged with the system under test (TODO: link to SUT). We call this a Trace (TODO: link to core concepts).

We call each turn of data exchange an Interaction. Think of an Interaction as a single API call to your system under test, with some inputs and some outputs.

.. note::
   For detailed explanations of these concepts, see :doc:`core-concepts`.

For our simple Q&A bot, we can represent a single turn as a trace with just one interaction. The inputs and outputs can be anything the bot supports, as long as they are serializable to JSON. For now, we'll assume our bot takes an input string (question) and returns a string (the answer).

.. code-block:: python

   from giskard.checks import Trace, Interaction, TestCase
   from giskard.checks.builtin import Groundedness

   # Create the interaction: this is a single turn of data exchange
   interaction = Interaction(
       inputs="What is the capital of France?",
       outputs="The capital of France is Paris.",  # generated by the bot
   )

   # The trace represents the full history of data exchange we want to test.
   trace = Trace.from_interactions(interaction)

In practice, we'll get the outputs directly from the bot, or maybe from a dataset of previously recorded interactions.

We can now create a test case that will check that the answer is grounded in the context information. A test case is simply a the union of an interaction trace and a list of checks that will be applied:

.. code-block:: python

   from giskard.checks import TestCase
   from giskard.checks.builtin import Groundedness

    # Define a test case
    test_case = TestCase(
        trace=trace,
        checks=[
            Groundedness(
                name="answer is grounded",
                answer_key="last.outputs",
                context="""France is a country in Western Europe. Its capital
                           and largest city is Paris, known for the Eiffel Tower
                           and the Louvre Museum."""
            )
        ],
    )

Note how we created the groundedness check:

- ``name``: this is an (optional) name for the check, to make it easier to interpret the results
- ``answer_key``: this is the key (in JSONPath) to the answer in the trace. In this case we want to check the ``outputs`` attribute of the last interaction in the trace (this is the default)
- ``context``: this is the context information that will be used to check if the answer is grounded. Note that a ``context_key`` is also available if we want to dynamically load the context from the trace itself (see next example).

We can now run the test case and inspect the results:

.. code-block:: python

    result = await test_case.run()

    print(result)

TODO: result block, description


Structuring the interactions
----------------------------

As mentioned above, in practice the interaction inputs and outputs can take any form as long as they are serializable to JSON. For example, our bot could take input in the form of an OpenAI message object and return a structured output like this:

.. code-block:: json

   {
       "answer": "The capital of France is Paris.",
       "confidence": 0.93,
       "documents": [
            "France is a country in Western Europe. Its capital and largest city is Paris, known for the Eiffel Tower and the Louvre Museum.",
            "The Eiffel Tower is a wrought-iron lattice tower in Paris. It was completed in 1889."
        ]
   }

We can easily create a trace based on this format, and adapt our test case:

.. code-block:: python

    from giskard.checks import Interaction, Trace, TestCase
    from giskard.checks.builtin import GreaterThan, Groundedness

    interaction = Interaction(
        inputs={"role": "user", "content": "What is the capital of France?"},
        outputs={
            "answer": "The capital of France is Paris.",
            "confidence": 0.93,
            "documents": ["France is a country in Western Europe. Its capital and largest city is Paris, known for the Eiffel Tower and the Louvre Museum.", "The Eiffel Tower is a wrought-iron lattice tower in Paris. It was completed in 1889."]
        },
    )

    trace = Trace.from_interactions(interaction)

    test_case = TestCase(
        trace=trace,
        checks=[
            Groundedness(
                name="answer is grounded",
                answer_key="last.outputs.answer",
                context_key="last.outputs.documents",
            ),
            GreaterThan(
                name="confidence is high",
                key="last.outputs.confidence",
                threshold=0.90,
            ),

        ],
    )

Note how this time we used ``context_key`` to obtain the context from the documents present in the trace itself. This is a common case for RAG systems. We also added a check to ensure the confidence is high.

We can now run the test case and inspect the results:

.. code-block:: python

    await test_case.run()


TODO: result block

This will give us a result object with the results of the checks.


Dynamic interactions
--------------------

In practice, we'll often want to create the ``outputs`` automatically from the system we are testing. The checks framework provides a simple way to do that using the ``InteractionSpec`` class.

Differently from static interactions, ``InteractionSpec`` allows both inputs and outputs to be generated at test time.

For example, our simple Q&A bot could be implemented using the OpenAI API:
.. code-block:: python

    from openai import OpenAI

    client = OpenAI()

    def get_answer(inputs: str) -> dict:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": inputs}],
        )
        return response.choices[0].message.content

We can now create an interaction spec that will use this function to generate the outputs:

.. code-block:: python

    from giskard.checks import InteractionSpec

    interaction = InteractionSpec(
        inputs="What is the capital of France?",
        outputs=get_answer
    )

    # TODO: Kevin how do I create a simple test case from an interaction spec?
    trace = Trace.from_interactions(interaction)

    test_case = TestCase(
        trace=trace,
        checks=[
            Groundedness(
                name="answer is grounded",
                answer_key="last.outputs.answer",
                context_key="last.outputs.documents",
            )
        ],
    )

No need to specify outputs anymore!

Note that also inputs can be dynamically generated! This is especially useful when you are testing multi-turn scenarios. For example, you can generate the inputs based on the previous interactions.

Check out the :doc:`multi-turn` guide for more details on how to test multi-turn scenarios.
